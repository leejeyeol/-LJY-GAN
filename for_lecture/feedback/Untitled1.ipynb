{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"F3qTqi3qnvh9","colab_type":"code","colab":{}},"source":["import numpy as np\n","def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n","\n","    N, C, H, W = input_data.shape\n","    out_h = (H + 2*pad - filter_h)//stride + 1\n","    out_w = (W + 2*pad - filter_w)//stride + 1\n","\n","    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n","    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n","\n","    for y in range(filter_h):\n","        y_max = y + stride*out_h\n","        for x in range(filter_w):\n","            x_max = x + stride*out_w\n","            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n","\n","col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3S08kAA6WaK","colab_type":"code","colab":{}},"source":["class Convolution:\n","    def __init__(self, W, b, stride=1, pad=0):\n","       self.W = W\n","       self.b = b\n","       self.stride = stride\n","       self.pad = pad\n","\n","       self.x = None\n","       self.col = None\n","       self.col_W = None\n","\n","       self.dW = None\n","       self.db = None\n","\n","    def forward(self, x):\n","        FN, C, FH, FW = self.W.shape\n","        N, C, H, W = x.shape\n","        out_h = 1 + int((H + 2*self.apd - FH) / self.stride)\n","        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n","\n","        col = im2col(x, FH, FW, self.stride, self.pad)\n","        print(\"input data -> im2col is\")\n","        print(col)\n","        col_W = self.W.reshape(FN, -1).T\n","        print(\"Weight = filter ... -> im2col is\")\n","        print(col_W)\n","\n","        out = np.dot(col, col_W) + self.b\n","        print(\"affine 연산 수행 결과\")\n","        print(out)\n","\n","        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n","\n","        self.x = x\n","        self.col = col\n","        self.col_W = col_W\n","\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_lf80Dr76G3","colab_type":"code","colab":{}},"source":["filter_num = 1\n","input_channels = 1\n","\n","x1 = np.array([[0,0,0,0,0],[0,1,2,3,0],[0,4,5,6,0],[0,7,8,9,0],[0,0,0,0,0]]).reshape(1, input_channels, 5, 5)\n","print(\"input data is\")\n","print(x1)\n","\n","W1 = np.array([[0,0,1],[0,1,0],[1,0,0]]).reshape([filter_num, input_channels, 3, 3])\n","b1 = np.zeros(filter_num)\n","\n","print(\"weight = filter = kernel = mask is\")\n","print(W1)\n","\n","conv1 = Convolution(W1, b1)\n","y=conv1.forward(x1)\n","\n","print(\"convolution 수행 결과\")\n","print(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sPoRsJeM8uQO","colab_type":"code","colab":{}},"source":["class MNIST_classifier_CNN(nn.Module):\n","    def __init__(self, class_num):\n","        super().__init__()\n","        self.class_num = class_num\n","\n","        self.conv_net = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","\n","         self.conv_net = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5),\n","            nn.BatchNorm2d(20),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)   \n","        )\n","        self.fc_net = nn.Sequential(\n","            nn.Linear(320,50),\n","            nn.BatchNorm1d(50),\n","            nn.ReLU(),\n","            nn.Linear(50,self.class_num),\n","            nn.Softmax()\n","        )\n","    def forward(self, x):\n","        feature = self.conv_net(x):\n","        feature = self.feature.view(-1,320)\n","        y = self.fc_net(feature)\n","        return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HmGd7IwW-SLF","colab_type":"code","colab":{}},"source":["def weight_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        m.weight.data.normal_(0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)\n","    elif classname.find('Linear') != -1:\n","        m.weight.data.normal_(0.0, 0.02)\n","        m.bias.data.fill_(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f5IbHCEd_Ahp","colab_type":"code","colab":{}},"source":["train_loss_list = []\n","val_loss_list = []\n","net.train()\n","for epoch in range(epochs):\n","    for i, (X, t) in enumerate(train_loader):\n","        X = X.cuda()\n","        t = one_hot_embedding(t, 10).cuda()\n","\n","        Y = net(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vAtecoomZSj7","colab_type":"code","colab":{}},"source":["import numpy as np\n","def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n","    \n","    N, C, H, W = input_data.shape\n","    out_h = (H + 2*pad - filter_h)//stride + 1\n","    out_w = (W + 2*pad - filter_w)//stride + 1\n","\n","    img = np.pad(input_data, [(0,0), (0,0), (pad,pad), (pad,pad)], 'contant')\n","    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n","\n","    for y in range(filter_h):\n","        y_max = y + stride*out_h\n","        for x in range(filter_w)\n","            x_max = x + stride*out_w\n","            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n","\n","    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n","    return col"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nJE88e1-aza6","colab_type":"code","colab":{}},"source":["class Convolution:\n","    def __init__(self, W, b, stride=1, pad=0):\n","        self.W = W\n","        self.b = b\n","        self.stride = stride\n","        self.pad = pad\n","\n","        self.x = None\n","        self.col = None\n","        self.col_W = None\n","\n","        self.dW = None\n","        self.db= None\n","\n","    def forward(self, x):\n","        FN, C, FH, FW = self.W.shape\n","        N, C, H, W = x.shape\n","        out_h = 1 + int(H + 2*self.pad - FH) / self.stride)\n","        out_w = 1 + int(W + 2*self.pad - FW) / self.stride)\n","\n","        col = im2col(x, FH, FW, self.stride, self.pad)\n","        print(\"input data -> im2col is\")\n","        print(col)\n","        col_W = self.W.reshape(FN, -1).T\n","        print(\"Weight = filter ... -> im2col is\")\n","        print(col_W)\n","\n","        out = np.dot(col, col_W) + self.b\n","        print(\"affine 연산 수행 결과\")\n","        print(out)\n","\n","        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n","\n","        self.x = x\n","        self.col = col\n","        self.col_W = col_W\n","\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GRLNviVHcRwI","colab_type":"code","colab":{}},"source":["filter_num = 1\n","input_channels = 1\n","\n","x1 = np.array([[0,0,0,0,0],[0, 1, 2, 3, 0],[0,4,5,6,0],[0,7,8,9,0],[0,0,0,0,0]]).reshape(1, input_channels, 5, 5)\n","print(\"input data is\")\n","print(x1)\n","\n","W1 = np.array([[0,0,1],[0,1,0],[1,0,0]]).reshape([filter_num, input_channels, 3, 3])\n","b1 = np.zeros(filter_num)\n","\n","print(\"weight =filter = kernel = mask is\")\n","print(W1)\n","\n","conv1 = Convolution(W1, b1)\n","y=conv1.forward(x1)\n","\n","print(\"convolution 수행 결과\")\n","print(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmXHUbODdjSP","colab_type":"code","colab":{}},"source":["class MNIST_classifier_CNN(nn.Module):\n","    def __init__(self, class_num):\n","        super().__init__()\n","        self.class_num = class_num\n","\n","        self.conv_net = nn.Seuquential(\n","            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(in_channels=10, out_cahnnels=20, kernel_size=5),\n","            nn.BatchNorm2d(20),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.fc_net = nn.Sequential(\n","            nn.Linear(320,50),\n","            nn.BatchNorm1d(50),\n","            nn.ReLU(),\n","            nn.Linear(50,self.class_num),\n","            nn.Softmax()\n","        )\n","    def forward(self, x):\n","        feature = self.conv_net(x)\n","        feature = feature.view(-1,320)\n","        y = self.fc_net(feature)\n","        return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Gd_Dcmzd-_5","colab_type":"code","colab":{}},"source":["def weight_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        m.weight.data.normal_(0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)\n","    elif classname.find('Linear')!=-1:\n","      m.weight.data.normal_(0.0, 0.02)\n","      m.bias.data.fill_(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fpv278vvfE3_","colab_type":"code","colab":{}},"source":["train_loss_list = []\n","val_loss_list = []\n","net.train()\n","for epoch in range(epochs):\n","    for i, (X, t) in enumerate(train_loader):\n","        X = X.cuda()\n","        t = one_hot_embedding(t, 10).cuda()\n","\n","        Y = net(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qKuxwPnh_V78","colab_type":"code","colab":{}},"source":["class MNIST_classifier_FCN(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super().__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","\n","        self.network1 = nn.Sequential(\n","            nn.Linear(self.input_size, self.hidden_size),\n","            nn.Sigmoid(),\n","            nn.Linear(self.hidden_size, self.output_size),\n","            nn.Softmax()\n","        )\n","\n","    def forward(self, x):\n","        y = self.network1(x)\n","        return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCmINdZt5gJE","colab_type":"code","colab":{}},"source":["class MNIST_classifier_CNN(nn.Module):\n","    def __init__(self, class_num):\n","        super().__init__()\n","        self.class_num = class_num\n","\n","        self.conv_net = nn.Seuquential(\n","            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","\n","            nn.Conv2d(in_channels=10, out_cahnnels=20, kernel_size=5),\n","            nn.BatchNorm2d(20),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.fc_net = nn.Sequential(\n","            nn.Linear(320,50),\n","            nn.BatchNorm1d(50),\n","            nn.ReLU(),\n","            nn.Linear(50,self.class_num),\n","            nn.Softmax()\n","        )\n","    def forward(self, x):\n","        feature = self.conv_net(x)\n","        feature = feature.view(-1,320)\n","        y = self.fc_net(feature)\n","        return y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6sPWd7hs6kCU","colab_type":"code","colab":{}},"source":["fc_net = MNIST_classifier_FCN(input_size=784, hidden_size=50, output_size=10)\n","conv_net = MNIST_classifier_CNN(class_num=10)\n","\n","print(\"fc_net's parameters\")\n","fc_num_weight = 0\n","for parameter in fc_net.parameters():\n","    print(parameter.shape)\n","    fc_num_weight+=np.asarray(parameterl.shape).prod()\n","\n","\n","\n","print(\"conv_net's parameters\")\n","conv_num_weight = 0\n","for parameter in conv_net.parameters():\n","    print(parameter.shape)\n","    conv_num_weight+=np.asarray(parameter.sahpe).prod()\n","\n","print(\"The number of fc_net's parameters\")\n","print(fc_num_weight)\n","\n","print(\"The number of conv_net's parameters\")\n","print(conv_num_weight)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZwiYAOsp7fVx","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-dtGpyI_7uUu","colab_type":"code","colab":{}},"source":["import os\n","os.mkdir(\"/content/gdrive/My Drive/AI\")\n","with open()\n","    f.write('Hello Google Drive colab !')\n","!cat /content/gdrive/My\\ Drive/AI/hello.txt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5AxNdlkH8GCR","colab_type":"code","colab":{}},"source":["class MNIST_CNN_Encoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.encoder = nn.Sequential(\n","            nn.Conv2d(1, 16, 3, stride=3, padding=1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=2),\n","            nn.Conv2d(16, 8 ,3, stride=2, padding=1),\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2, stride=1)\n","        )\n","\n","    def forward(self, x):\n","        z = self.encoder(x)\n","        return z\n","\n","\n","  class MNIST_CNN_Decoder(nn.Module):\n","      def __init__(self):\n","          super().__init__()\n","\n","          self.decoder = nn.Sequential(\n","              nn.ConvTranspose2d(8, 16, 3, stride=2),\n","              nn.ReLU(True),\n","              nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),\n","              nn.ReLU(True),\n","              nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),\n","              nn.Tanh()\n","          )\n","      def forward(self, z):\n","          x_ = self.decoder(z)\n","          return x_\n","\n","epochs = 10\n","learning_rate = 0.01\n","batch_size = 100\n","loss_function = nn.MSELoss()\n","\n","dataset = datasets.MNIST('../data', train=True,\n","                         download=True, transform=transforms.Compose([\n","        transforms.ToTensor()\n","        , transforms.Normalize((0.5,), (0.5,))\n","    ]))\n","\n","encoder = MNIST_CNN_Encoder().cuda()\n","encoder.apply(weight_init)\n","\n","decoder  = MNIST_CNN_Decoder().cuda()\n","decoder.apply(weight_init)\n","\n","net_params = list(encoder.parameters())+list(decoder.parameters())\n","optimizer = optim.Adam(net_params, betas=(0.5, 0.999), lr=learning_rate)\n","\n","train_loss_list = []\n","val_loss_list = []\n","encoder.train()\n","decoder.train()\n","for epoch in range(epochs):\n","    for i, (X, _) in enumerate(train_loader):\n","        X = X.cuda()\n","        z = encoder(X)\n","        recon_X = decoder(z)\n","\n","        loss = loss_function(recon_X), X\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if i % 100 == 0:\n","            with torch.no_grad():\n","                val_100_loss = []\n","                for (X, _) in valid_loader:\n","                    X = X.cuda()\n","                    z = encoder(X)\n","                    recon_X = decoder(z)\n","                    loss = loss_function(recon_X, X)\n","\n","                    val_100_loss.append(loss)\n","                train_loss_list.append(loss)\n","                val_loss_list.append(np.asarray(val_100_loss.sum() / lend(valid_loader))\n","        print(\"[%d/%d][%d/%d] loss : %f\" % (i, len(train_loader), epochs, epochs, loss))\n","\n","project_root_path = '/content/gdrive/My Drive/AI'\n","encoder_save_path = '%s/pretrained_encoder.pth' % (project_root_path)\n","torch.save(encoder.state_dict(), encoder_save_path)\n","\n","print(\"testing\")\n","encoder.eval()\n","decoder.eval()\n","correct = 0\n","with torch.no_grad():\n","    for i, (X, _) in enumerate(test_loader):\n","        X = X.cuda()\n","        z = encoder(X)\n","        recon_X = decoder(z)\n","\n","        print(\"오토인코더 테스트 결과\")\n","        for i in range(5):\n","            plt.imshow(X[i].cpu().reshape(28, 28))\n","            plt.gray()\n","            plt.show()\n","\n","            plt.imshow(recond_X[i],cpu().reshape(28, 28))\n","            plt.gray()\n","            plt.show()\n","        break\n","\n","plt.plot(np.column_stack((train_loss_list, val_loss_list)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f5CGwtxPz1EA","colab_type":"code","colab":{}},"source":["class MNIST_FCN(nn.Module):\n","    def __init__(self. class_num):\n","        super().__init__()\n","        self.class_num = class_num\n","\n","        self.fc_net = nn.Sequential(\n","            nn.Linear(32, 50),\n","            nn.ReLU(),\n","            nn.Linear(50, self.class_num),\n","            nn.Softmax()\n","        )\n","    def forward(self, x):\n","        x = x.view(-1, 32)\n","        y = self.fc_net(x)\n","        return y\n","\n","fcn = MNIST_FCN(class_num10).cuda()\n","fcn.apply(weight_init)\n","\n","pretrained_encoder = MNIST_CNN_Encoder().cuda()\n","project_root_path = '/content/grdrive/My Drive/AI'\n","encoder_save_path = '%s/pretrained_encoder.pth' % (project_root_path)\n","saved_weights = torch.load(encoder_save_path)\n","pretrained_encoder.load_state_dict(saved_weights)\n","\n","pochs = 5\n","learning_rate = 0.01\n","batch_size = 100\n","loss_function = nn.BCELoss()\n","\n","optimizer = optim.Adam(list(fcn.parameters())+list(pretrained_encoder()), betas=(0.5, 0.999), lr=learning_rate)\n","\n","train_loss_list = []\n","fcn.train()\n","for epoch in range(epochs):\n","    for i, (X, t) in enumerate(train_loader):\n","        X = X.cuda()\n","        t = one_hot_embedding(t, 10).cuda()\n","        z = pretrained_encoder(X)\n","        Y = fcn(z)\n","\n","        loss = loss_function(Y, t)\n","        train_loss_list.append(loss)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        print(\"[%d/%d][%d/%d] loss : %f\"%(i, len(train_loader), epoch,epochs, loss))\n","\n","project_root_path = '/content/gdrive/My Drive/AI'\n","encoder_save_path = '%s/pretrained_encoder.pth' % (project_root_path)\n","torch.save(encoder.state_dict)(), encoder_save_path)\n","\n","print(\"testing\")\n","encoder.eval()\n","decoder.eval()\n","correct = 0\n","with torch.no_grad():\n","    for i, (X, _) in enumerate(test_loader):\n","        X = X.cuda()\n","        z = encoder(X)\n","        recon_X = decoder(z)\n","\n","        print(\"오토인코더 테스트 결과\")\n","        for i in range(5):\n","            plt.imshow(X[i].cpu().reshape(28, 28))\n","            plt.gray()\n","            plt.show()\n","\n","            plt.imshow()"],"execution_count":0,"outputs":[]}]}